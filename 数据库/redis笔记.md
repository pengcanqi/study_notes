redis笔记

# 一、数据结构

## 1. SDS

SDS除了用来保存数据库中的字符串值之外，SDS还被用作缓冲区：AOF模块中的AOF缓冲区，以及客户端状态中的输入缓冲区

### 1.1 sds优势：

- ### 更快速的获取字符串长度

  ​	我们都知道Java的字符串有提供length方法，列表有提供size方法，我们可以直接获取大小。但是C却不一样，更偏向底层实现，所以没有直接的方法使用。这样就带来一个问题，如果我们想要获取某个数组的长度，就只能从头开始遍历，当遇到第一个'\0'则表示该数组结束。这样的速度太慢了，不能每次因为要获取长度就变量数组。所以设计了SDS数据结构，在原来的字符数组外面增加总长度，和已用长度，这样每次直接获取已用长度即可。复杂度为O(1)。

- ### 数据安全，不会截断

  ​		如果传统字符串保存图片，视频等二进制文件，中间可能出现'\0'，如果按照原来的逻辑，会造成数据丢失。所以可以用已用长度来表示是否字符数组已结束。

- ### 杜绝缓冲区溢出

- ### 减少修改字符串长度所需要的的内存重分配次数

  ```
  1.空间预分配：小于1M，空间每次翻倍，大于1M，空间每次加1M，最大大小512M
  2.惰性空间释放
  3.初始大小为本身大小，不会多分配空间
  ```

### 1.2 编码方式

- ​	embstr：将redisobject和数据对象sdshdr连续存放，在分配时只分配一次空间，适用于小字符串
- ​    raw：将redisobject和数据对象sdshdr不连续存放，在分配时只分配两次空间

## 2. 双端链表

除了链表建之外，发布与订阅、慢查询、监视器等功能也用到了链表，Redis服务器本身还用链表保存多个客户端的状态信息，以及用链表来构建客户端输出缓冲区。

redis的链表是自带头尾指针的双端链表

## 3. 字典

dict 是 Redis 服务器中出现最为频繁的复合型数据结构，除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。

```c
struct RedisDb {
     dict* dict; // all keys  key=>value
     dict* expires; // all expired keys key=>long(timestamp)
     ... 
} 
 
struct zset {
     dict *dict; // all values  value=>score
     zskiplist *zsl;
} 
```

### 字典内部结构图

### 扩容缩容

- 扩容条件

  当服务器目前没有执行BGSAVE命令或者BGREWRITEAOF命令时，并且哈希表的负载因子大于等于1
  当服务器目前正在执行BGSAVE命令或则BGREWRITEAOF命令，并且哈希表的负载因子大于等于5

      负载因子的计算方式为：负载因子 = 哈希表已保存结点数量/哈希表大小(used/size)
  ```
  执行BGSAVE命令或者BGREWRITEAOF命令的过程中，Redis需要创建当前服务器进程的子进程，而大多数操作系统都采用 写时复制（copy-on-write）来优化子进程的使用效率，所以在子进程存在期间，服务器会提高负载因子的阈值，从而避免在子进程存在期间进行哈希表扩展操作，避免不必要的内存写入操作，最大限度地节约内存。 
  参考文献：https://blog.csdn.net/qq_34556414/article/details/108399543
  ```

- 缩容条件

  元素个数低于数组长度的10%，切无需考虑是否在进行bgsave

### 渐进式rehash

hash过程耗时很长，而redis又是单线程处理的，如果在线程内同步rehash操作，会阻塞线程，使相应变慢。所以采用渐进式hash方式。

- 对桶位中元素进行写操作时，对整个桶进进行惰性迁移。
- 定时任务对未完成的迁移的桶位进行主动迁移

## 4.整数集合

整数集合是集合键底层实现之一，当一个集合只包含整数元素，且数据不多的时候，redis就会使用整数集合来作为底层实现。

```c
typedef struct intset {
    
    // 编码方式
    uint32_t encoding;

    // 集合包含的元素数量
    uint32_t length;

    // 保存元素的数组
    int8_t contents[];
} intset;
```

### 升级

- 整数集合的encoding保存了数据元素的编码，当数组元素中的最大值大于阈值时，编码会进行升级。
- 他可以保存int_16t,int_32t,int_64t这三类编码的数组。
- 没有降级的过程

## 5. 压缩列表

当hash、list、zset结构中元素较少，且列表项要么是小整数值，要么是长度比较短的字符串时候，redis会使用压缩列表来做列表建的底层实现。

```c
typedef struct zlentry {
    unsigned int prevrawlensize; /* encode前一个entry的字节长度*/
    unsigned int prevrawlen;     /* 前一个entry长度*/
    unsigned int lensize;        /* encode当前字节长度*/
    unsigned int len;            /* 实际长度 */
    unsigned int headersize;     /* prevrawlensize + lensize. */
    unsigned char encoding;      /* Set to ZIP_STR_* or ZIP_INT_* depending on
                                    the entry encoding. However for 4 bits
                                    immediate integers this can assume a range
                                    of values and must be range-checked. */
    unsigned char *p;            /* Pointer to the very start of the entry, that
                                    is, this points to prev-entry-len field. */
} zlentry;

```

### previous属性

prevlen属性以字节为单位，记录了压缩列表中前一个节点的长度，其长度可以是 1 字节或者 5 字节：

1. 如果前一节点的长度小于254字节，那么prevlen属性的长度为1字节， 前一节点的长度就保存在这一个字节里面。
2. 如果前一节点的长度大于等于254字节，那么prevlen属性的长度为5字节,第一字节会被设置为**0xFE**，之后的四个字节则用于保存前一节点的长度。

### 通过previous双向遍历

假设我们有一个指向当前节点起始地址的指针c，那我们获取前一个节点的起始地址p只需要：

```c
p = c - current_entry.previous_entry_length
```

### 连锁更新

再思考一个问题，为什么prevlen的长度要么是1字节要么是5字节呢？为啥没有2字节、3字节、4字节这些中间态的长度呢？要解答这个问题就引出了一个关键问题：连锁更新问题。

试想这样一种增加节点的场景：

```
如果在压缩列表的头部增加一个新节点，并且长度大于254字节，所以其后面节点的prevlen必须是5字节，然而在增加新节点之前其prevlen是1字节，必须进行扩展，极端情况下如果一直都需要扩展那么将产生连锁反应。
```

理解了连锁更新问题，再来看看为什么要么1字节要么5字节的问题吧，如果是2-4字节那么可能产生连锁反应的概率就更大了，相反直接给到最大5字节会大大降低连锁更新的概率，所以笔者也认为这种内存的小小浪费也是值得的。

## 6. RedisObject

每次当我们在redis数据库新创建一个值键对时，至少会创建两个对象，一个用于作为建对象，一个用于作为值对象。redis每个对象都由一个redisObject的结构表示，该结构中与保存数据相关的三个属性分别是：type,encoding,ptr

```c
/*
 * Redis 对象
 */
typedef struct redisObject {
 
    // 类型
    unsigned type:4;
 
    // 对齐位
    unsigned notused:2;
 
    // 编码方式
    unsigned encoding:4;
 
    // LRU 时间（相对于 server.lruclock，于server.lruclock比较得到对象空转时间）
    unsigned lru:22;
 
    // 引用计数
    int refcount;
 
    // 指向对象的值
    void *ptr;
 
}
```

而我们常用的Redis对象有：字符串对象，列表对象，集合对象，有序集合对象，hash对象这五种。这些对象底层的编码方式，也可以说是底层数据结构，可能有不同的实现方式。具体对应关系如下

![对象与编码](C:\Users\pengc\Desktop\study\study_note_image\数据库\redis\对象与编码.png)

## 7.键空间

### 7. 1 定义

redis是一个键值对数据库服务器，每个数据库都有一个redisDb结构表示，其中redisDb结构的dict字典保存了数据库中的所有键值对，我们将这个字典称之为**键空间**。

- 键空间中的键也就是数据库的键，都是一个字符串对象。
- 键空间的芝也就是数据库的值，每一个值可以是上文所述的常用对象。

### 7.2   读写键空间时的维护操作

- 更新redisObject中的lru
- 发现该键过期则删除
- watch命令监视了某个键，那么服务器在对被监视的键进行修改之后，会将整个键标记为脏
- 每次修改一次键后，对脏键计数器值增加1，这个计数器会触发服务器的持久化以及复制操作

### 7.3  键空间结构示例

![数据库键空间例子](C:\Users\pengc\Desktop\study\study_note_image\数据库\redis\数据库键空间例子.png)

## 8. 过期键处理

所有的过期键维护在redisDb结构中的expires字典里，它的键和键空间dict中的键指向同一个对象，所以不会出现任何重复对象，也不会浪费任何空间。它的值是过期时间戳。

### 删除策略

```
惰性删除：
	读写操作都会先判断键是否已经过期，如已经过期则删除

定期删除：
	定时任务从expires中随机抽取一定数量的随机键进行检查，删除其中的过期键。
```

### 在持久化过程中对过期键的处理

#### RDB

```
生成RDB文件不会把已经过期的键写入RDB文件中
主库加载RDB文件不会把已经过期的键写入RDB文件中，从库不区分，但是一般也会从主库复制的时候删除掉过期键。
```

#### AOF

```
过期键已经过期，但是没有惰性删除和定期删除时，AOF文件无影响。只有在已经删除后，会在AOF文件中追加一条DEL命令。在AOF重写时，也不会把过期的键保存到新的AOF文件中。
```

### 复制过程中对过期键的处理

```
参考文献：https://blog.csdn.net/xiaochao_bos/article/details/103140678
```

在老版本的redis中，在读取过期键的时候，从库不会主动删除过期键*（这种统一、中心化的过期键删除策略可以保持主从数据一致性，若从库可以删，那么主库延长过期时间，可能存在并发问题）*，而是直接返回原始值*（但这里有问题）*，所以可能导致从库读取到脏数据的问题。

在在redis 3.2-rc1版本中之后版本的redis中，redis加入了一个新特性来解决主从不一致导致读取到过期数据的问题，如果key已过期，当前访问的是master则返回null；当前访问的是从库，且执行的是只读命令也返回null。

## 发布订阅

虽然redis实现了发布订阅（publish/subscribe）的功能，但是在通常的情况下是不推荐使用的，如果想使用消息队列这种功能，最好还是使用专业的各种MQ中间件，例如rabbitMQ，rockedMQ,activitedMQ等。概要说一下就是，PUBLISH和SUBSCRIBE的缺陷在于客户端必须一直在线才能接收到消息，断线可能会导致客户端丢失消息，除此之外，旧版的redis可能会由于订阅者消费不够快而变的不稳定导致崩溃，甚至被管理员杀掉

**第一个原因是和redis系统的稳定性有关**。对于旧版的redis来说，如果一个客户端订阅了某个或者某些频道，但是它读取消息的速度不够快，那么不断的积压的消息就会使得redis输出缓冲区的体积越来越大，这可能会导致redis的速度变慢，甚至直接崩溃。也可能会导致redis被操作系统强制杀死，甚至导致操作系统本身不可用。新版的redis不会出现这种问题，因为它会自动断开不符合client-output-buffer-limit pubsub配置选项要求的订阅客户端

**第二个原因是和数据传输的可靠性有关。**任何网络系统在执行操作时都可能会遇到断网的情况。而断线产生的连接错误通常会使得网络连接两端中的一端进行重新连接。如果客户端在执行订阅操作的过程中断线，那么客户端将会丢失在断线期间的消息，这在很多业务场景下是不可忍受的。

## RDB

### BGSAVE

```text
那么RDB单机持久化时，过程中新写入的值是否会持久化了？
先说答案：不会
分析原因：RDB持久化的过程使用，为了节省内存，使用了copy on write 的策略，与父进程共享同一内存，此时若想当然认为新新写入的也会一同被子进程持久化，则错了。“写时复制“技术，在只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程，所以新
写入数据时，子进程会单独复制一份写之前的数据，此时此段子进程与父进程是各自独立维护的。当父进程对其中一个页面的数据进行修改时，会将被共享的页面复 制一份分离出来，然后 对这个复制的页面进行修改。这时 子进程 相应的页面是 没有变化的，还是进程产生时那一瞬间的数据。随着父进程修改操作的持续进行，越来越多的共享页面将会被分离出来，内存就会持续增长，但是也不会超过原有数据内存的两倍大小（Redis实例里的冷数据占的比例往往是比较高的，所以很少出现所有页面都被分离的情况）。
```

### 自动间隔性保存

**自动保存的判断依据**：在某一段时间内，redis的写操作数量有没有达到阈值。

**配置参数**

- 阈值参数：serverParams
- 写操作计数器：dirty
- 上一次保存完成的时间:lastsave

通过配置serverParams参数，调整自动保存的触发时间。当redis执行写命令时，会对dirty计数器进行累加操作。而redis的服务器周期性操作函数severCron会定时执行一次，该函数用于对正在进行的服务器进行位，其中一项重要工作就是遍历serverParams数组判断是否达到自动保存的条件。

## AOF

### aof缓冲刷盘配置

- always：将aof缓冲区的内容同步到aof文件
- everysec：将aof缓冲区内容每秒同步一次
- no：由操作系统来决定何时刷盘

## 混合持久化

**旧版本redis恢复策略**：默认aof，如果没有配置aof则才是RDB

**Redis4.0混合持久化**：重启 Redis 时，如果使用 RDB 来恢复内存状态，会丢失大量数据。而如果只使用 AOF 日志重放，那么效率又太过于低下。Redis 4.0 提供了混合持久化方案，将 RDB 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自 RDB  持久化开始到持久化结束这段时间发生的增量 AOF 日志，通常这部分日志很小。

## 事件

### 事件分类

- 文件事件：读事件，写事件
- 时间时间：周期性时间，定时时间
  1. 删除数据库的key
  2. 触发RDB和AOF持久化
  3. 主从同步
  4. 集群化保活
  5. 关闭清理死客户端链接
  6. 统计更新服务器的内存、key数量等信息

### 时间事件的组织方式

以list结构组成一个链表

![时间事件](C:\Users\pengc\Desktop\study\study_note_image\数据库\redis\时间事件.png)

### 事件的执行

我们都知道redis是单线程模型，时间自然也是单线程执行的。而文件时间，采用的是reactor模式，用io多路复用，获取要执行的文件事件。而我们知道io多路复用，在select或者epoll.wait的时候，是会阻塞的，当然也可以传递超时时间，到达超时时间后不管有无读写请求，均可返回。而我们知道时间时间维护着一些很重要的功能，如果文件事件阻塞过长，会导致时间事件执行受影响。那么我们如何制定文件事件的阻塞事件呢？

```
遍历时间事件列表，获取最近到期的时间事件的时间，设置epoll的超时时间不超过此时间。这样，我们就能大致保证时间事件按时执行。由于时间事件在文件事件之后执行，并且事件之间不会出现抢占，所以时间事件的实际处理时间一般会比设定的时间稍晚一些。
```

